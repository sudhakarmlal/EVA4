import cv2
import numpy as np
import os
from glob import glob
%matplotlib inline

import numpy as np
import matplotlib.pyplot as plt
import io
from itertools import groupby
import cv2
from tqdm.auto import tqdm
from pathlib import Path
from time import time
from torchvision import datasets
from torch.utils.data import DataLoader, Dataset , random_split
from PIL import Image
from torchvision.transforms import transforms
import os
from glob import glob
import torch
import torchvision
from torch import nn


from tqdm import tqdm
import os
from glob import glob
import matplotlib.pyplot as plt
import random
import cv2


def saveimage(tensors, name, figsize=(50,50), *args, **kwargs):
  filename= IMG_DIR+ name
  try:
    tensors = tensors.detach().cpu()
  except: 
    pass
  grid_tensor1= torchvision.utils.make_grid(tensors,*args, **kwargs)
  grid_image1= grid_tensor1.permute(1,2,0)
  plt.figure(figsize=figsize)
  plt.imshow(grid_image1)
  plt.xticks([])
  plt.yticks([])
  plt.savefig(filename, bbox_inches = 'tight')
  plt.show()
  

def mapimages(bg_file_names,fg_file_names,mask_file_names,dp_file_names,fg_bg_file_names):
    forground_image_names = []
    bg_mask_img_names = []
    bg_dp_img_names = []
    bg_fg_bg_img_names = []

    mask_img_names  = []
    dp_img_names = []
    fg_images_names = []
    fg_bg_img_names = []

    for i in range(len(fg_file_names)):
      fg_str = fg_file_names[i].split('/')[-1]
      fg_name = fg_str[0:fg_str.rfind('.jpg')]
      print(fg_name)
      forground_image_names.append(fg_name)

    for i in range(len(forground_image_names)):
      for j in range(40):
        print(bg_file_names[j])
        bg_str = bg_file_names[j].split('_')[-1]
        print(bg_str[0:bg_str.rfind('.jpg')])
        bg_num  = bg_str[0:bg_str.rfind('.jpg')]
        search_str_mask ="bg_mask"+forground_image_names[i][6:]
        search_str_mask = search_str_mask + "_" +bg_num+"_"
        print(search_str_mask)
        search_str_depth_fg_bg ="depth_fg_bg"+forground_image_names[i][6:]
        search_str_depth_fg_bg =search_str_depth_fg_bg + "_" +bg_num +"_"
        print(search_str_depth_fg_bg)

        search_str_fg_bg ="fg_bg"+forground_image_names[i][6:]
        search_str_fg_bg =search_str_fg_bg + "_" +bg_num +"_"
        print(search_str_fg_bg)
  
        for k in range(len(mask_file_names)):
          mask_str = mask_file_names[k].split('/')[-1]
          fg_depth_bg_str =dp_file_names[k].split('/')[-1]
          fg_bg_str = fg_bg_file_names[k].split('/')[-1]
          if mask_str.startswith(search_str_mask):
            mask_img_names.append(mask_file_names[k])
            bg_mask_img_names.append(bg_file_names[j])
          if fg_bg_str.startswith(search_str_fg_bg):
            fg_bg_img_names.append(fg_bg_file_names[k])
            bg_fg_bg_img_names.append(bg_file_names[j])
            #fg_images_names.append(fg_file_names[i])  
          if fg_depth_bg_str.startswith(search_str_depth_fg_bg):
            dp_img_names.append(dp_file_names[k])
            bg_dp_img_names.append(bg_file_names[j])
            fg_images_names.append(fg_file_names[i]) 
    return fg_images_name,dp_img_names,mask_img_names,bg_mask_img_names,bg_dp_img_names,fg_bg_img_names,bg_fg_bg_img_names
    
 
 def train( batch, model,scheduler, criterion1,criterion2, device, train_loader, optimizer, epoch,iteration,writer):
  other_time = 0
  correct = 0
  start = time()
  other_s = time()
  model.train()
  other_e = time()
  other_time += other_e - other_s
  data_load_time = 0
  model_time = 0
  meow_time = 0
  pbar = tqdm(train_loader)
  for batch_idx, data in enumerate(pbar):
    other_s = time()
    optimizer.zero_grad()
    other_e = time()
    other_time += other_e - other_s
    load_s = time()
    data["bg_image"] = data["bg_image"].to(device)
    data["fg_bg_image"] = data["fg_bg_image"].to(device)
    data["ms_bg_image"] = data["ms_bg_image"].to(device)
    data["dp_image"] = data["dp_image"].to(device)
    load_e = time()
    data_load_time += load_e - load_s
    model_s = time() 
    optimizer.zero_grad()
    output=model(data)    
    #loss= criterion(output,data["ms_bg_image"])
    #loss1 = criterion(output[0],data["ms_bg_image"])
    #loss2 = criterion(output[1],data["dp_image"])
    loss1 = criterion1(output[0],data["ms_bg_image"])
    loss2 = criterion2(output[1],data["dp_image"])
    loss = 2*loss1 + loss2
    pbar.set_description(desc= f'l1={round(loss1.item(),4)} l2={round(loss2.item(),4)}')
    loss.backward()
    optimizer.step()
    model_e = time()
    model_time += model_e - model_s
    other_s = time()
    if batch_idx % 250 == 0:
      writer.add_scalar('training loss', loss.item() / 1000, epoch * iteration + batch_idx)
    if batch_idx % 10 == 0:
      torch.cuda.empty_cache()
    if batch_idx % 50 == 0:
      print('Train Epoch : {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(epoch,batch_idx*len(data),len(train_loader.dataset), 
                                                                    100.*batch_idx/len(train_loader), loss.item()))
    if epoch == 4:
      if batch_idx % iteration == 0:
        saveimage(data["fg_bg_image"], f"/{batch}_3CFGBGORG.jpg")
        saveimage(output[0], f"/{batch}_3CMSBGPDCT.jpg")
        saveimage(data["ms_bg_image"], f"/{batch}_3CMSBGORG.jpg")
        saveimage(output[1], f"/{batch}_3CDPBGPDCT.jpg")      
        saveimage(data["dp_image"], f"/{batch}_3CDPBGORG.jpg")  
    other_e = time()
    other_time += other_e - other_s
  end = time()
    #if batch_idx % 5000 == 0:
    #  show_pred(output.detach().cpu,nrow=2)
    #  show(output,nrow=4)
    #if batch_idx % 50 == 0:
    #  torch.save(model.state_dict(), PATH/f"{batch_idx}.pth")  
  #if epoch == 2:
  #torch.save(model.state_dict(), PATH/f"model_fn_{epoch}.pth")  
  print(f'Total Execution time : {end-start:.2f} s')
  print(f'Model Execution Time : {model_time:.2f} s')
  print(f'Data Loading Time : {data_load_time:.2f} s')
  print(f'Other Execution Time : {other_time:.2f} s')
  

def executeModel(batch,train_dl,model, fromepoch, toepoch):
  iteration= len(train_dl)
  for epoch in range(fromepoch, toepoch):
    #modeldata = trainmodeldepth(batch, model,scheduler, criterion1,criterion2, device, train_dl, optim, epoch,iteration,writer)
    train( batch, model,scheduler, criterion1,criterion2, device, train_dl, optim, epoch,iteration,writer)
    scheduler.step()  
  torch.save(model.state_dict(), PATH/f"modelup3C_{batch}.pth")